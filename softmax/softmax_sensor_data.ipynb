{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48654243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:07.153656Z",
     "start_time": "2023-02-09T13:33:04.502880Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "from torch.nn import functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fc5c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:09.938907Z",
     "start_time": "2023-02-09T13:33:09.923948Z"
    }
   },
   "outputs": [],
   "source": [
    "## 初代数读取方案\n",
    "# import os\n",
    "# print(os.path.abspath('.'))\n",
    "\n",
    "\n",
    "# #读取训练数据集 和  测试数据集\n",
    "# all_feature = pd.read_csv(\"../data/train_set.csv\")\n",
    "# all_test = pd.read_csv(\"../data/test_set.csv\")\n",
    "# # 先是pands类型的数据 进行数据切片 分为 数据和label  \n",
    "# # feature 是 float32  label 是长整型\n",
    "# feature = all_feature.iloc[:,0:-1].astype(np.float32)\n",
    "# label = all_feature.iloc[:,-1].astype(np.compat.long)\n",
    "\n",
    "# test_feature = all_test.iloc[:,0:-1].astype(np.float32)\n",
    "# test_label = all_test.iloc[:,-1].astype(np.compat.long)\n",
    "\n",
    "# # 把 俩个变量 feature 和 label 做成 list \n",
    "# class GetLoader(torch.utils.data.Dataset):\n",
    "# \t# 初始化函数，得到数据\n",
    "#     def __init__(self, data_root, data_label):\n",
    "#         self.data = data_root\n",
    "#         self.label = data_label\n",
    "#     # index是根据batchsize划分数据后得到的索引，最后将data和对应的labels进行一起返回\n",
    "#     def __getitem__(self, index):\n",
    "#         data = self.data[index]\n",
    "#         labels = self.label[index]\n",
    "#         return data, labels\n",
    "#     # 该函数返回数据大小长度，目的是DataLoader方便划分，如果不知道大小，DataLoader会一脸懵逼\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "# # 再把np array 类型的数据转化为tensor 类型\n",
    "# feature = torch.tensor(feature.values)\n",
    "# label = torch.tensor(label.values).type(torch.long)\n",
    "\n",
    "# test_feature = torch.tensor(test_feature.values)\n",
    "# test_label = torch.tensor(test_label.values).type(torch.long)\n",
    "\n",
    "# #生成训练集和测试集\n",
    "# dataset = GetLoader(feature,label)\n",
    "\n",
    "# test_dataset = GetLoader(test_feature,test_label)\n",
    "\n",
    "# test_feature\n",
    "\n",
    "# next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c850369",
   "metadata": {},
   "source": [
    "## 后续学习 输入的宽度应该不止70个数据了 （可以修改的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bcaef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:11.683318Z",
     "start_time": "2023-02-09T13:33:11.564636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv', '30ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv', '30ppms1_dset.csv', '40ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv', '30ppms1_dset.csv', '40ppms1_dset.csv', '50ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv', '30ppms1_dset.csv', '40ppms1_dset.csv', '50ppms1_dset.csv', '60ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv', '30ppms1_dset.csv', '40ppms1_dset.csv', '50ppms1_dset.csv', '60ppms1_dset.csv', '70ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv', '30ppms1_dset.csv', '40ppms1_dset.csv', '50ppms1_dset.csv', '60ppms1_dset.csv', '70ppms1_dset.csv', '80ppms1_dset.csv']\n",
      "['100ppms1_dset.csv', '10ppms1_dset.csv', '20ppms1_dset.csv', '30ppms1_dset.csv', '40ppms1_dset.csv', '50ppms1_dset.csv', '60ppms1_dset.csv', '70ppms1_dset.csv', '80ppms1_dset.csv', '90ppms1_dset.csv']\n"
     ]
    }
   ],
   "source": [
    "##找到当前存放数据的路劲 （批量读取数据）##\n",
    "os.chdir(r'C:\\\\Users\\\\86136\\\\PycharmProjects\\\\pythonProject\\\\AI -learn from zero\\\\tem_dataset')\n",
    "##  要切换到的新路径  可以%pwd 查看当前路径\n",
    "file_chdir = os.getcwd() ##  获取当前路径\n",
    "file_name_list=[]\n",
    "file_list=[] \n",
    "for root,dirs,files in os.walk(file_chdir):  ## file_chdir :代表需要遍历的根文件夹  root :表示正在遍历的文件夹的名字（根/子）\n",
    "                                            ## dirs :记录正在遍历的文件夹下的子文件夹集合  files:记录正在遍历的文件夹中的文件集合(list形式)\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[-1] =='.csv': ## os.path.splitext()  分离文件名与扩展名；默认返回(fname,fextension)元组 切片后-1 表示后缀\n",
    "            file_name_list.append(file)\n",
    "            print(file_name_list)\n",
    "            file_list.append(pd.read_csv(file,index_col=0))\n",
    "\n",
    "feature = np.empty(shape=(0,3)) ## 创建空的np array 必须要有shape 参数\n",
    "label = np.empty(shape=(0,3))\n",
    "## 将label 和 feature 分开\n",
    "for i in range(len(file_list)):\n",
    "    label = np.append(label,np.array(file_list[i].iloc[:,-1]))\n",
    "    feature = np.append(feature,np.array(file_list[i].iloc[:,0:-1]))\n",
    "\n",
    "## 将数据分为多组的 输入和label  （这里label 用于做one hot 只能是一维的输入  因此不适用 reshape）\n",
    "feature= feature.reshape(-1,1,70)\n",
    "label = label/10\n",
    "\n",
    "## 这里的splite 已经自带 shuffle \n",
    "features,test_feature,labels,test_label =  train_test_split(feature, label, test_size=0.2) ## 特定的库中 适用的分离 训练集和测试集的方法\n",
    "\n",
    "## 将数据类型转化为tensor\n",
    "features = torch.from_numpy(features).float().reshape(-1,70,1)  ## 这里重置了数据 为三维的tensor\n",
    "labels = torch.from_numpy(labels).long()\n",
    "test_feature =torch.from_numpy(test_feature).float().reshape(-1,70,1)\n",
    "test_label = torch.from_numpy(test_label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bca27da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:12.632451Z",
     "start_time": "2023-02-09T13:33:12.597569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.5197],\n",
       "          [0.5203],\n",
       "          [0.5210],\n",
       "          [0.5200],\n",
       "          [0.5187],\n",
       "          [0.5207],\n",
       "          [0.5191],\n",
       "          [0.5200],\n",
       "          [0.5197],\n",
       "          [0.5194],\n",
       "          [0.5197],\n",
       "          [0.5216],\n",
       "          [0.5197],\n",
       "          [0.5203],\n",
       "          [0.5191],\n",
       "          [0.5197],\n",
       "          [0.5197],\n",
       "          [0.5203],\n",
       "          [0.5187],\n",
       "          [0.5191],\n",
       "          [0.5203],\n",
       "          [3.0871],\n",
       "          [3.6313],\n",
       "          [3.7921],\n",
       "          [3.8347],\n",
       "          [3.8421],\n",
       "          [3.8369],\n",
       "          [3.8437],\n",
       "          [3.8334],\n",
       "          [3.8269],\n",
       "          [3.8269],\n",
       "          [3.8166],\n",
       "          [3.8089],\n",
       "          [3.8105],\n",
       "          [3.8018],\n",
       "          [3.7915],\n",
       "          [3.7828],\n",
       "          [3.7876],\n",
       "          [3.7783],\n",
       "          [3.7718],\n",
       "          [3.7738],\n",
       "          [3.7670],\n",
       "          [3.7576],\n",
       "          [3.7499],\n",
       "          [3.7564],\n",
       "          [3.7480],\n",
       "          [3.7422],\n",
       "          [3.7451],\n",
       "          [3.7370],\n",
       "          [3.7312],\n",
       "          [3.7344],\n",
       "          [2.5867],\n",
       "          [1.5347],\n",
       "          [0.9801],\n",
       "          [0.7275],\n",
       "          [0.6180],\n",
       "          [0.5648],\n",
       "          [0.5413],\n",
       "          [0.5281],\n",
       "          [0.5216],\n",
       "          [0.5184],\n",
       "          [0.5158],\n",
       "          [0.5149],\n",
       "          [0.5139],\n",
       "          [0.5123],\n",
       "          [0.5136],\n",
       "          [0.5113],\n",
       "          [0.5116],\n",
       "          [0.5113],\n",
       "          [0.5116]],\n",
       " \n",
       "         [[0.4375],\n",
       "          [0.4375],\n",
       "          [0.4385],\n",
       "          [0.4372],\n",
       "          [0.4375],\n",
       "          [0.4382],\n",
       "          [0.4382],\n",
       "          [0.4372],\n",
       "          [0.4372],\n",
       "          [0.4372],\n",
       "          [0.4375],\n",
       "          [0.4375],\n",
       "          [0.4375],\n",
       "          [0.4379],\n",
       "          [0.4382],\n",
       "          [0.4375],\n",
       "          [0.4375],\n",
       "          [0.4379],\n",
       "          [0.4375],\n",
       "          [0.4375],\n",
       "          [0.4375],\n",
       "          [2.1649],\n",
       "          [3.3062],\n",
       "          [3.6027],\n",
       "          [3.6877],\n",
       "          [3.7138],\n",
       "          [3.7228],\n",
       "          [3.7151],\n",
       "          [3.7083],\n",
       "          [3.7054],\n",
       "          [3.6903],\n",
       "          [3.6871],\n",
       "          [3.6855],\n",
       "          [3.6729],\n",
       "          [3.6677],\n",
       "          [3.6632],\n",
       "          [3.6513],\n",
       "          [3.6481],\n",
       "          [3.6400],\n",
       "          [3.6307],\n",
       "          [3.6294],\n",
       "          [3.6172],\n",
       "          [3.6139],\n",
       "          [3.6120],\n",
       "          [3.5985],\n",
       "          [3.5962],\n",
       "          [3.5956],\n",
       "          [3.5830],\n",
       "          [3.5807],\n",
       "          [3.5798],\n",
       "          [3.5691],\n",
       "          [2.7520],\n",
       "          [1.5882],\n",
       "          [0.9479],\n",
       "          [0.6673],\n",
       "          [0.5464],\n",
       "          [0.4904],\n",
       "          [0.4646],\n",
       "          [0.4524],\n",
       "          [0.4453],\n",
       "          [0.4414],\n",
       "          [0.4398],\n",
       "          [0.4382],\n",
       "          [0.4372],\n",
       "          [0.4366],\n",
       "          [0.4359],\n",
       "          [0.4359],\n",
       "          [0.4356],\n",
       "          [0.4343],\n",
       "          [0.4340]],\n",
       " \n",
       "         [[0.5519],\n",
       "          [0.5513],\n",
       "          [0.5513],\n",
       "          [0.5526],\n",
       "          [0.5506],\n",
       "          [0.5529],\n",
       "          [0.5510],\n",
       "          [0.5516],\n",
       "          [0.5516],\n",
       "          [0.5516],\n",
       "          [0.5522],\n",
       "          [0.5510],\n",
       "          [0.5522],\n",
       "          [0.5513],\n",
       "          [0.5519],\n",
       "          [0.5510],\n",
       "          [0.5519],\n",
       "          [0.5513],\n",
       "          [0.5513],\n",
       "          [0.5522],\n",
       "          [2.2416],\n",
       "          [3.4838],\n",
       "          [3.7654],\n",
       "          [3.8430],\n",
       "          [3.8740],\n",
       "          [3.8723],\n",
       "          [3.8643],\n",
       "          [3.8678],\n",
       "          [3.8582],\n",
       "          [3.8575],\n",
       "          [3.8453],\n",
       "          [3.8388],\n",
       "          [3.8379],\n",
       "          [3.8298],\n",
       "          [3.8308],\n",
       "          [3.8198],\n",
       "          [3.8098],\n",
       "          [3.8134],\n",
       "          [3.8053],\n",
       "          [3.8053],\n",
       "          [3.7953],\n",
       "          [3.7989],\n",
       "          [3.7879],\n",
       "          [3.7870],\n",
       "          [3.7831],\n",
       "          [3.7757],\n",
       "          [3.7783],\n",
       "          [3.7676],\n",
       "          [3.7715],\n",
       "          [3.7628],\n",
       "          [3.2395],\n",
       "          [2.0283],\n",
       "          [1.2389],\n",
       "          [0.8632],\n",
       "          [0.6953],\n",
       "          [0.6180],\n",
       "          [0.5816],\n",
       "          [0.5648],\n",
       "          [0.5542],\n",
       "          [0.5503],\n",
       "          [0.5471],\n",
       "          [0.5458],\n",
       "          [0.5439],\n",
       "          [0.5432],\n",
       "          [0.5426],\n",
       "          [0.5416],\n",
       "          [0.5419],\n",
       "          [0.5400],\n",
       "          [0.5419],\n",
       "          [0.5406]],\n",
       " \n",
       "         [[0.3911],\n",
       "          [0.3908],\n",
       "          [0.3911],\n",
       "          [0.3921],\n",
       "          [0.3918],\n",
       "          [0.3927],\n",
       "          [0.3921],\n",
       "          [0.3924],\n",
       "          [0.3921],\n",
       "          [0.3921],\n",
       "          [0.3924],\n",
       "          [0.3924],\n",
       "          [0.3921],\n",
       "          [0.3924],\n",
       "          [0.3918],\n",
       "          [0.3915],\n",
       "          [0.3915],\n",
       "          [0.3915],\n",
       "          [0.3911],\n",
       "          [0.3918],\n",
       "          [0.3905],\n",
       "          [2.6483],\n",
       "          [3.3697],\n",
       "          [3.5778],\n",
       "          [3.6423],\n",
       "          [3.6590],\n",
       "          [3.6600],\n",
       "          [3.6542],\n",
       "          [3.6471],\n",
       "          [3.6400],\n",
       "          [3.6313],\n",
       "          [3.6233],\n",
       "          [3.6152],\n",
       "          [3.6065],\n",
       "          [3.5985],\n",
       "          [3.5914],\n",
       "          [3.5836],\n",
       "          [3.5762],\n",
       "          [3.5688],\n",
       "          [3.5627],\n",
       "          [3.5556],\n",
       "          [3.5488],\n",
       "          [3.5418],\n",
       "          [3.5347],\n",
       "          [3.5285],\n",
       "          [3.5221],\n",
       "          [3.5160],\n",
       "          [3.5102],\n",
       "          [3.5034],\n",
       "          [3.4976],\n",
       "          [3.4912],\n",
       "          [2.2813],\n",
       "          [1.2643],\n",
       "          [0.7717],\n",
       "          [0.5635],\n",
       "          [0.4743],\n",
       "          [0.4343],\n",
       "          [0.4143],\n",
       "          [0.4037],\n",
       "          [0.3995],\n",
       "          [0.3966],\n",
       "          [0.3927],\n",
       "          [0.3921],\n",
       "          [0.3921],\n",
       "          [0.3921],\n",
       "          [0.3911],\n",
       "          [0.3905],\n",
       "          [0.3895],\n",
       "          [0.3905],\n",
       "          [0.3895]],\n",
       " \n",
       "         [[0.5484],\n",
       "          [0.5490],\n",
       "          [0.5484],\n",
       "          [0.5497],\n",
       "          [0.5477],\n",
       "          [0.5493],\n",
       "          [0.5471],\n",
       "          [0.5477],\n",
       "          [0.5481],\n",
       "          [0.5487],\n",
       "          [0.5481],\n",
       "          [0.5464],\n",
       "          [0.5506],\n",
       "          [0.5484],\n",
       "          [0.5484],\n",
       "          [0.5484],\n",
       "          [0.5487],\n",
       "          [0.5487],\n",
       "          [0.5490],\n",
       "          [0.5484],\n",
       "          [1.9819],\n",
       "          [3.4451],\n",
       "          [3.7477],\n",
       "          [3.8359],\n",
       "          [3.8682],\n",
       "          [3.8682],\n",
       "          [3.8723],\n",
       "          [3.8617],\n",
       "          [3.8511],\n",
       "          [3.8533],\n",
       "          [3.8437],\n",
       "          [3.8456],\n",
       "          [3.8356],\n",
       "          [3.8247],\n",
       "          [3.8282],\n",
       "          [3.8173],\n",
       "          [3.8198],\n",
       "          [3.8086],\n",
       "          [3.8079],\n",
       "          [3.8037],\n",
       "          [3.7950],\n",
       "          [3.7976],\n",
       "          [3.7850],\n",
       "          [3.7924],\n",
       "          [3.7818],\n",
       "          [3.7728],\n",
       "          [3.7776],\n",
       "          [3.7676],\n",
       "          [3.7715],\n",
       "          [3.7628],\n",
       "          [3.3723],\n",
       "          [2.1443],\n",
       "          [1.2998],\n",
       "          [0.8912],\n",
       "          [0.7072],\n",
       "          [0.6238],\n",
       "          [0.5835],\n",
       "          [0.5655],\n",
       "          [0.5545],\n",
       "          [0.5500],\n",
       "          [0.5468],\n",
       "          [0.5455],\n",
       "          [0.5442],\n",
       "          [0.5439],\n",
       "          [0.5432],\n",
       "          [0.5423],\n",
       "          [0.5423],\n",
       "          [0.5406],\n",
       "          [0.5410],\n",
       "          [0.5410]],\n",
       " \n",
       "         [[0.5487],\n",
       "          [0.5477],\n",
       "          [0.5493],\n",
       "          [0.5481],\n",
       "          [0.5493],\n",
       "          [0.5481],\n",
       "          [0.5493],\n",
       "          [0.5484],\n",
       "          [0.5490],\n",
       "          [0.5481],\n",
       "          [0.5490],\n",
       "          [0.5490],\n",
       "          [0.5487],\n",
       "          [0.5487],\n",
       "          [0.5490],\n",
       "          [0.5490],\n",
       "          [0.5497],\n",
       "          [0.5490],\n",
       "          [0.5487],\n",
       "          [0.5490],\n",
       "          [0.5490],\n",
       "          [2.4475],\n",
       "          [3.5205],\n",
       "          [3.7725],\n",
       "          [3.8453],\n",
       "          [3.8588],\n",
       "          [3.8717],\n",
       "          [3.8637],\n",
       "          [3.8646],\n",
       "          [3.8524],\n",
       "          [3.8550],\n",
       "          [3.8421],\n",
       "          [3.8437],\n",
       "          [3.8337],\n",
       "          [3.8247],\n",
       "          [3.8263],\n",
       "          [3.8150],\n",
       "          [3.8040],\n",
       "          [3.8105],\n",
       "          [3.8011],\n",
       "          [3.8044],\n",
       "          [3.7947],\n",
       "          [3.7866],\n",
       "          [3.7899],\n",
       "          [3.7792],\n",
       "          [3.7844],\n",
       "          [3.7747],\n",
       "          [3.7634],\n",
       "          [3.7696],\n",
       "          [3.7615],\n",
       "          [3.7631],\n",
       "          [3.1773],\n",
       "          [1.9732],\n",
       "          [1.2086],\n",
       "          [0.8484],\n",
       "          [0.6847],\n",
       "          [0.6128],\n",
       "          [0.5761],\n",
       "          [0.5600],\n",
       "          [0.5506],\n",
       "          [0.5464],\n",
       "          [0.5439],\n",
       "          [0.5419],\n",
       "          [0.5419],\n",
       "          [0.5390],\n",
       "          [0.5397],\n",
       "          [0.5400],\n",
       "          [0.5377],\n",
       "          [0.5384],\n",
       "          [0.5377]],\n",
       " \n",
       "         [[0.5200],\n",
       "          [0.5203],\n",
       "          [0.5207],\n",
       "          [0.5213],\n",
       "          [0.5213],\n",
       "          [0.5213],\n",
       "          [0.5203],\n",
       "          [0.5210],\n",
       "          [0.5213],\n",
       "          [0.5203],\n",
       "          [0.5216],\n",
       "          [0.5216],\n",
       "          [0.5213],\n",
       "          [0.5210],\n",
       "          [0.5213],\n",
       "          [0.5216],\n",
       "          [0.5210],\n",
       "          [0.5210],\n",
       "          [0.5203],\n",
       "          [0.5216],\n",
       "          [0.5203],\n",
       "          [2.8403],\n",
       "          [3.5798],\n",
       "          [3.7692],\n",
       "          [3.8343],\n",
       "          [3.8469],\n",
       "          [3.8446],\n",
       "          [3.8475],\n",
       "          [3.8372],\n",
       "          [3.8263],\n",
       "          [3.8292],\n",
       "          [3.8173],\n",
       "          [3.8073],\n",
       "          [3.8111],\n",
       "          [3.8011],\n",
       "          [3.7944],\n",
       "          [3.7957],\n",
       "          [3.7876],\n",
       "          [3.7783],\n",
       "          [3.7754],\n",
       "          [3.7750],\n",
       "          [3.7660],\n",
       "          [3.7602],\n",
       "          [3.7631],\n",
       "          [3.7547],\n",
       "          [3.7483],\n",
       "          [3.7518],\n",
       "          [3.7448],\n",
       "          [3.7361],\n",
       "          [3.7280],\n",
       "          [3.7344],\n",
       "          [2.8245],\n",
       "          [1.6906],\n",
       "          [1.0539],\n",
       "          [0.7614],\n",
       "          [0.6331],\n",
       "          [0.5725],\n",
       "          [0.5448],\n",
       "          [0.5303],\n",
       "          [0.5223],\n",
       "          [0.5220],\n",
       "          [0.5168],\n",
       "          [0.5155],\n",
       "          [0.5155],\n",
       "          [0.5145],\n",
       "          [0.5139],\n",
       "          [0.5142],\n",
       "          [0.5129],\n",
       "          [0.5120],\n",
       "          [0.5110]],\n",
       " \n",
       "         [[0.4359],\n",
       "          [0.4369],\n",
       "          [0.4369],\n",
       "          [0.4356],\n",
       "          [0.4366],\n",
       "          [0.4359],\n",
       "          [0.4366],\n",
       "          [0.4362],\n",
       "          [0.4362],\n",
       "          [0.4362],\n",
       "          [0.4369],\n",
       "          [0.4362],\n",
       "          [0.4362],\n",
       "          [0.4372],\n",
       "          [0.4366],\n",
       "          [0.4359],\n",
       "          [0.4362],\n",
       "          [0.4362],\n",
       "          [0.4359],\n",
       "          [0.4366],\n",
       "          [1.2147],\n",
       "          [3.1164],\n",
       "          [3.5421],\n",
       "          [3.6726],\n",
       "          [3.7187],\n",
       "          [3.7209],\n",
       "          [3.7245],\n",
       "          [3.7138],\n",
       "          [3.7096],\n",
       "          [3.6958],\n",
       "          [3.6932],\n",
       "          [3.6903],\n",
       "          [3.6748],\n",
       "          [3.6742],\n",
       "          [3.6623],\n",
       "          [3.6590],\n",
       "          [3.6491],\n",
       "          [3.6462],\n",
       "          [3.6323],\n",
       "          [3.6326],\n",
       "          [3.6207],\n",
       "          [3.6184],\n",
       "          [3.6172],\n",
       "          [3.6046],\n",
       "          [3.6049],\n",
       "          [3.5949],\n",
       "          [3.5920],\n",
       "          [3.5782],\n",
       "          [3.5788],\n",
       "          [3.5785],\n",
       "          [3.3726],\n",
       "          [2.0699],\n",
       "          [1.1835],\n",
       "          [0.7697],\n",
       "          [0.5919],\n",
       "          [0.5123],\n",
       "          [0.4756],\n",
       "          [0.4575],\n",
       "          [0.4482],\n",
       "          [0.4437],\n",
       "          [0.4414],\n",
       "          [0.4398],\n",
       "          [0.4388],\n",
       "          [0.4382],\n",
       "          [0.4369],\n",
       "          [0.4362],\n",
       "          [0.4362],\n",
       "          [0.4356],\n",
       "          [0.4353],\n",
       "          [0.4353]],\n",
       " \n",
       "         [[0.5203],\n",
       "          [0.5207],\n",
       "          [0.5210],\n",
       "          [0.5203],\n",
       "          [0.5210],\n",
       "          [0.5200],\n",
       "          [0.5207],\n",
       "          [0.5197],\n",
       "          [0.5216],\n",
       "          [0.5200],\n",
       "          [0.5203],\n",
       "          [0.5197],\n",
       "          [0.5216],\n",
       "          [0.5197],\n",
       "          [0.5210],\n",
       "          [0.5200],\n",
       "          [0.5213],\n",
       "          [0.5200],\n",
       "          [0.5197],\n",
       "          [0.5184],\n",
       "          [0.5245],\n",
       "          [2.3631],\n",
       "          [3.4834],\n",
       "          [3.7480],\n",
       "          [3.8198],\n",
       "          [3.8379],\n",
       "          [3.8514],\n",
       "          [3.8421],\n",
       "          [3.8446],\n",
       "          [3.8347],\n",
       "          [3.8256],\n",
       "          [3.8250],\n",
       "          [3.8140],\n",
       "          [3.8021],\n",
       "          [3.8066],\n",
       "          [3.7953],\n",
       "          [3.7986],\n",
       "          [3.7892],\n",
       "          [3.7812],\n",
       "          [3.7828],\n",
       "          [3.7741],\n",
       "          [3.7673],\n",
       "          [3.7696],\n",
       "          [3.7602],\n",
       "          [3.7541],\n",
       "          [3.7557],\n",
       "          [3.7467],\n",
       "          [3.7402],\n",
       "          [3.7435],\n",
       "          [3.7325],\n",
       "          [3.7354],\n",
       "          [3.2821],\n",
       "          [2.0351],\n",
       "          [1.2270],\n",
       "          [0.8377],\n",
       "          [0.6670],\n",
       "          [0.5880],\n",
       "          [0.5519],\n",
       "          [0.5345],\n",
       "          [0.5255],\n",
       "          [0.5203],\n",
       "          [0.5174],\n",
       "          [0.5171],\n",
       "          [0.5142],\n",
       "          [0.5133],\n",
       "          [0.5129],\n",
       "          [0.5129],\n",
       "          [0.5123],\n",
       "          [0.5123],\n",
       "          [0.5104]],\n",
       " \n",
       "         [[0.5145],\n",
       "          [0.5145],\n",
       "          [0.5145],\n",
       "          [0.5139],\n",
       "          [0.5155],\n",
       "          [0.5145],\n",
       "          [0.5149],\n",
       "          [0.5142],\n",
       "          [0.5152],\n",
       "          [0.5149],\n",
       "          [0.5145],\n",
       "          [0.5149],\n",
       "          [0.5139],\n",
       "          [0.5155],\n",
       "          [0.5152],\n",
       "          [0.5152],\n",
       "          [0.5145],\n",
       "          [0.5162],\n",
       "          [0.5142],\n",
       "          [0.5155],\n",
       "          [2.0886],\n",
       "          [3.4264],\n",
       "          [3.7274],\n",
       "          [3.8118],\n",
       "          [3.8359],\n",
       "          [3.8475],\n",
       "          [3.8405],\n",
       "          [3.8327],\n",
       "          [3.8340],\n",
       "          [3.8240],\n",
       "          [3.8150],\n",
       "          [3.8166],\n",
       "          [3.8069],\n",
       "          [3.7986],\n",
       "          [3.7999],\n",
       "          [3.7915],\n",
       "          [3.7831],\n",
       "          [3.7847],\n",
       "          [3.7767],\n",
       "          [3.7692],\n",
       "          [3.7712],\n",
       "          [3.7622],\n",
       "          [3.7554],\n",
       "          [3.7570],\n",
       "          [3.7483],\n",
       "          [3.7419],\n",
       "          [3.7454],\n",
       "          [3.7354],\n",
       "          [3.7399],\n",
       "          [3.7315],\n",
       "          [3.3017],\n",
       "          [2.0599],\n",
       "          [1.2350],\n",
       "          [0.8429],\n",
       "          [0.6692],\n",
       "          [0.5896],\n",
       "          [0.5516],\n",
       "          [0.5319],\n",
       "          [0.5242],\n",
       "          [0.5194],\n",
       "          [0.5165],\n",
       "          [0.5145],\n",
       "          [0.5142],\n",
       "          [0.5123],\n",
       "          [0.5123],\n",
       "          [0.5116],\n",
       "          [0.5116],\n",
       "          [0.5100],\n",
       "          [0.5107],\n",
       "          [0.5097]]]),\n",
       " tensor([ 9,  5, 10,  4, 10, 10,  9,  5,  9,  9])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 使用dataloder  和 tensordataset ： 把 多个tensor 变成 多元组 因此每个tensor的长度必须一致\n",
    "def load_array(data_arrays,batch_size,is_train = True):\n",
    "    dataset =data.TensorDataset(*data_arrays)   ## TensorDataset的作用是将多个的tensor 变成一个多元组  其中*data_array的第一维度长度必须相等\n",
    "    return data.DataLoader(dataset,batch_size,shuffle =False)\n",
    "def load_test(data_arrays,batch_size,is_test = False):\n",
    "    dataset =data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset,batch_size,shuffle =False)\n",
    "batch_size =10  # 超参数\n",
    "seed=10 ## 随机种子\n",
    "torch.manual_seed(seed)\n",
    "data_iter = load_array((features,labels),batch_size) # 训练集\n",
    "test_iter = load_test((test_feature,test_label),batch_size)  # 测试集\n",
    "\n",
    "next(iter(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc41223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:21.465684Z",
     "start_time": "2023-02-09T13:33:20.158624Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化权重（W）和偏置（b）\n",
    "device=d2l.try_gpu()\n",
    "num_inputs = 70\n",
    "num_hiddens = 10\n",
    "num_outputs = 10\n",
    "H = torch.zeros((batch_size, num_hiddens),requires_grad=True,device=device)\n",
    "W_xh =torch.normal(0, 0.01,size=(batch_size,num_hiddens),requires_grad=True,device=device)\n",
    "W_hh =torch.normal(0, 0.01,size=(num_hiddens,num_hiddens),requires_grad=True,device=device)\n",
    "b_h =torch.zeros(num_hiddens,requires_grad=True,device=device)\n",
    "W_hq = torch.normal(0, 0.01,size=(num_hiddens,num_outputs),requires_grad=True,device=device)\n",
    "b_q = torch.zeros((batch_size,num_outputs), requires_grad=True,device=device)\n",
    "params = [W_xh,W_hh,b_h,W_hq,b_q]\n",
    "all_params =[W_xh,W_hh,b_h,W_hq,b_q,H]\n",
    "# W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)  这是softmax的初始化\n",
    "# b = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "175e898f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:22.648919Z",
     "start_time": "2023-02-09T13:33:22.637949Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义softmax函数 \n",
    "# softmax的含义将 net 输出的矩阵的每一行 变化成 softmax的模式 \n",
    "#意思是需要将一行的元素做e指数求和 再用每个元素的e指数来除以它\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition  # 这里应用了广播机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb927fd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:22.993645Z",
     "start_time": "2023-02-09T13:33:22.971700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这里的net之定义了一个矩阵的乘法\n",
    "def net(data_feature,W_xh,W_hh,b_h,W_hq,b_q,H):\n",
    "    data_feature = torch.transpose(data_feature,0,1)\n",
    "    params = [W_xh,W_hh,b_h,W_hq,b_q]\n",
    "    for X in data_feature:\n",
    "        #print(f'X={X.shape}')\n",
    "        X =X.reshape(1,min(W_xh.shape[0],X.shape[0]))\n",
    "        X =X.to(device)\n",
    "        H = torch.tanh(torch.mm(X, W_xh)+ torch.mm(H, W_hh)+ b_h)\n",
    "        for p in params:\n",
    "            if p.grad is not None:\n",
    "#                 print(torch.sqrt(torch.sum(p.grad ** 2)))\n",
    "                norm= torch.sqrt(torch.sum(p.grad ** 2))\n",
    "                if norm > 1:\n",
    "                    for param in params:\n",
    "                        param.grad[:] *= 1 / norm  ## inplace 操作  直接改写\n",
    "    Y = torch.mm(H.reshape(10,10), W_hq) + b_q \n",
    "    Y =Y.to(device)\n",
    "    return softmax(Y)\n",
    "#    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b) ## softmax的返回值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2fe3e32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:23.493200Z",
     "start_time": "2023-02-09T13:33:23.487216Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这里的是调试的需求\n",
    "# y_hat=net(feature)\n",
    "# y_hat = y_hat.argmax(axis=1)\n",
    "# y_hat\n",
    "# cmp = y_hat.type(label.dtype) ==label\n",
    "# cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938162b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T05:22:26.484099Z",
     "start_time": "2022-11-01T05:22:26.473151Z"
    }
   },
   "source": [
    "y_ha = torch.tensor([[0.1,0.3,0.6],[0.2,0.3,0.5]])\n",
    "y = torch.tensor([0,2])\n",
    "\n",
    "y_ha[range(len(y_ha)),y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b65a0eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:24.785809Z",
     "start_time": "2023-02-09T13:33:24.766860Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这里的cross_entrop 是作为损失函数\n",
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1b248c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:25.128643Z",
     "start_time": "2023-02-09T13:33:25.112328Z"
    }
   },
   "outputs": [],
   "source": [
    "#cross_entropy(y_hat,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df3c9ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:25.632336Z",
     "start_time": "2023-02-09T13:33:25.626353Z"
    }
   },
   "outputs": [],
   "source": [
    "#比较真实的输出 和 label 的比较结果\n",
    "def accuracy(y_hat, y,device):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    y_hat = y_hat.to(device)\n",
    "    y = y.to(device)\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "487772e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:26.585489Z",
     "start_time": "2023-02-09T13:33:26.570528Z"
    }
   },
   "outputs": [],
   "source": [
    "#评估准确度 \n",
    "# 测试模型的时候一般定义为eval（）模式  因为这个时候只进行前向的求导 不更新权重\n",
    "#训练完train_datasets之后，model要来测试样本了。在model(test_datasets)之前，\n",
    "#需要加上model.eval(). 否则的话，有输入数据，即使不训练，它也会改变权值。\n",
    "#这是model中含有batch normalization层所带来的的性质。\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式  \n",
    "    metric = d2l.Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if X.shape[0]<batch_size:  ## =剩余数据不足batch_size 就舍弃\n",
    "                continue\n",
    "            else:\n",
    "                #print(f'xshape={X.shape}')\n",
    "                y=y.T.reshape(-1)\n",
    "                metric.add(accuracy(net(X,W_xh,W_hh,b_h,W_hq,b_q,H), y,device), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c110e7b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:27.332762Z",
     "start_time": "2023-02-09T13:33:27.327803Z"
    }
   },
   "outputs": [],
   "source": [
    "# class Accumulator:  #@save\n",
    "#     \"\"\"在n个变量上累加\"\"\"\n",
    "#     def __init__(self, n):\n",
    "#         self.data = [0.0] * n\n",
    "\n",
    "#     def add(self, *args):\n",
    "#         self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "#     def reset(self):\n",
    "#         self.data = [0.0] * len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759252f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:30.523593Z",
     "start_time": "2023-02-09T13:33:28.418260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10888888888888888"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(net, data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd2760c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:32.577375Z",
     "start_time": "2023-02-09T13:33:32.564422Z"
    }
   },
   "outputs": [],
   "source": [
    "# update 雅传如 W，b lr 哈有batch_size\n",
    "def updater(batch_size):\n",
    "    return d2l.sgd(params,lr,batch_size)  ## 这里把Ｈ　和　不含有Ｈ　的都试过　差别不大\n",
    "#    return d2l.sgd([W, b], lr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92a07355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:33.384649Z",
     "start_time": "2023-02-09T13:33:33.375671Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch_ch3(net, train_iter, loss, updater,device):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = d2l.Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        if X.shape[0]<batch_size:  ## =剩余数据不足batch_size 就舍弃\n",
    "            continue\n",
    "        else:\n",
    "            #print(f'x1={X.shape}')\n",
    "            y=y.T.reshape(-1)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X,W_xh,W_hh,b_h,W_hq,b_q,H) ## 补充参数\n",
    "            l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "#             print(f'l.mean{l.mean()}')\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数\n",
    "            l.sum().backward()\n",
    "#             print(f'l.sum{l.sum()}')\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y,device), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5cf841f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:36.018302Z",
     "start_time": "2023-02-09T13:33:34.862801Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "transform: failed to synchronize: cudaErrorAssert: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20596\\3415108308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_epoch_ch3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupdater\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20596\\3324114912.py\u001b[0m in \u001b[0;36mtrain_epoch_ch3\u001b[1;34m(net, train_iter, loss, updater, device)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# 使用定制的优化器和损失函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;31m#             print(f'l.sum{l.sum()}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mupdater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\glenn_pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\glenn_pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: transform: failed to synchronize: cudaErrorAssert: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "lr =0.01\n",
    "train_epoch_ch3(net,data_iter,cross_entropy,updater,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16f0ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:36.019299Z",
     "start_time": "2023-02-09T13:33:36.019299Z"
    }
   },
   "outputs": [],
   "source": [
    "# class Animator:  #@save\n",
    "#     \"\"\"在动画中绘制数据\"\"\"\n",
    "#     def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "#                  ylim=None, xscale='linear', yscale='linear',\n",
    "#                  fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "#                  figsize=(3.5, 2.5)):\n",
    "#         # 增量地绘制多条线\n",
    "#         if legend is None:\n",
    "#             legend = []\n",
    "#         d2l.use_svg_display()\n",
    "#         self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "#         if nrows * ncols == 1:\n",
    "#             self.axes = [self.axes, ]\n",
    "#         # 使用lambda函数捕获参数\n",
    "#         self.config_axes = lambda: d2l.set_axes(\n",
    "#             self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "#         self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "#     def add(self, x, y):\n",
    "#         # 向图表中添加多个数据点\n",
    "#         if not hasattr(y, \"__len__\"):\n",
    "#             y = [y]\n",
    "#         n = len(y)\n",
    "#         if not hasattr(x, \"__len__\"):\n",
    "#             x = [x] * n\n",
    "#         if not self.X:\n",
    "#             self.X = [[] for _ in range(n)]\n",
    "#         if not self.Y:\n",
    "#             self.Y = [[] for _ in range(n)]\n",
    "#         for i, (a, b) in enumerate(zip(x, y)):\n",
    "#             if a is not None and b is not None:\n",
    "#                 self.X[i].append(a)\n",
    "#                 self.Y[i].append(b)\n",
    "#         self.axes[0].cla()\n",
    "#         for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "#             self.axes[0].plot(x, y, fmt)\n",
    "#         self.config_axes()\n",
    "#         display.display(self.fig)\n",
    "#         display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97249ae0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:37.716296Z",
     "start_time": "2023-02-09T13:33:37.703331Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater,device):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.1, 1],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater,device)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da6d909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:33:41.397863Z",
     "start_time": "2023-02-09T13:33:41.105608Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20596\\4037820882.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# batch_size = 10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_ch3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdater\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20596\\2634554368.py\u001b[0m in \u001b[0;36mtrain_ch3\u001b[1;34m(net, train_iter, test_iter, loss, num_epochs, updater, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m                         legend=['train loss', 'train acc', 'test acc'])\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtrain_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch_ch3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdater\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0manimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20596\\3324114912.py\u001b[0m in \u001b[0;36mtrain_epoch_ch3\u001b[1;34m(net, train_iter, loss, updater, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m#print(f'x1={X.shape}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_xh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_hh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_h\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW_hq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_q\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## 补充参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"240.554688pt\" height=\"173.477344pt\" viewBox=\"0 0 240.554688 173.477344\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-02-09T21:33:41.375922</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 173.477344 \n",
       "L 240.554688 173.477344 \n",
       "L 240.554688 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "L 30.103125 10.999219 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m257a4321aa\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m257a4321aa\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(22.151563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m257a4321aa\" x=\"69.163125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(61.211563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m257a4321aa\" x=\"108.223125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(100.271563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m257a4321aa\" x=\"147.283125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(139.331563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m257a4321aa\" x=\"186.343125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(178.391563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m257a4321aa\" x=\"225.403125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(217.451563 164.197656)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m3f576dc054\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3f576dc054\" x=\"30.103125\" y=\"149.599219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(7.2 153.398438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3f576dc054\" x=\"30.103125\" y=\"121.879219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(7.2 125.678438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3f576dc054\" x=\"30.103125\" y=\"94.159219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.4 -->\n",
       "      <g transform=\"translate(7.2 97.958438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3f576dc054\" x=\"30.103125\" y=\"66.439219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.6 -->\n",
       "      <g transform=\"translate(7.2 70.238438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3f576dc054\" x=\"30.103125\" y=\"38.719219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.8 -->\n",
       "      <g transform=\"translate(7.2 42.518438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3f576dc054\" x=\"30.103125\" y=\"10.999219\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(7.2 14.798438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 30.103125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 225.403125 149.599219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 30.103125 149.599219 \n",
       "L 225.403125 149.599219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 30.103125 10.999219 \n",
       "L 225.403125 10.999219 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr =0.01\n",
    "# batch_size = 10\n",
    "num_epochs = 100\n",
    "train_ch3(net, data_iter, test_iter, cross_entropy, num_epochs, updater,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93917fbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:23:14.225130Z",
     "start_time": "2023-02-09T13:23:14.225130Z"
    }
   },
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2a214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-09T13:23:14.227125Z",
     "start_time": "2023-02-09T13:23:14.227125Z"
    }
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de6d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
