{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ce4f7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.790980Z",
     "start_time": "2022-11-14T03:27:01.741112Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_211000\\4014262994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\glenn_pytorch\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\glenn_pytorch\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tester\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\glenn_pytorch\\lib\\site-packages\\pandas\\testing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m from pandas._testing import (\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\glenn_pytorch\\lib\\site-packages\\pandas\\_testing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3054\u001b[1;33m \u001b[0mcython_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelectionMixin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'core'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043cdb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-20T11:55:34.024976Z",
     "start_time": "2022-09-20T11:55:33.979100Z"
    }
   },
   "source": [
    "## 老方法  用两个文件产生的数据进行学习 \n",
    "- read_date = pd.read_csv('data/train_set.csv') ##\n",
    "- test_data = pd.read_csv('data/test_set.csv') \n",
    "- feature_df = read_date.iloc[:,0:-1]\n",
    "- label_df = read_date.iloc[:,-1]\n",
    "- test_feature_df = test_data.iloc[:,0:-1]\n",
    "-test_label_df = test_data.iloc[:,-1]\n",
    "-features = torch.from_numpy(feature_df.values).float()\n",
    "-labels = torch.from_numpy(label_df.values).long()\n",
    "-test_feature =torch.from_numpy(test_feature_df.values).float()\n",
    "-test_label = torch.from_numpy(test_label_df.values).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8ccbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.794967Z",
     "start_time": "2022-11-14T03:27:01.794967Z"
    }
   },
   "outputs": [],
   "source": [
    "##找到当前存放数据的路劲 （批量读取数据）##\n",
    "os.chdir(r'C:\\\\Users\\\\86136\\\\PycharmProjects\\\\pythonProject\\\\AI -learn from zero\\\\tem_dataset')\n",
    "##  要切换到的新路径  可以%pwd 查看当前路径\n",
    "file_chdir = os.getcwd() ##  获取当前路径\n",
    "file_name_list=[]\n",
    "file_list=[] \n",
    "for root,dirs,files in os.walk(file_chdir):  ## file_chdir :代表需要遍历的根文件夹  root :表示正在遍历的文件夹的名字（根/子）\n",
    "                                            ## dirs :记录正在遍历的文件夹下的子文件夹集合  files:记录正在遍历的文件夹中的文件集合(list形式)\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[-1] =='.csv': ## os.path.splitext()  分离文件名与扩展名；默认返回(fname,fextension)元组 切片后-1 表示后缀\n",
    "            file_name_list.append(file)\n",
    "            print(file_name_list)\n",
    "            file_list.append(pd.read_csv(file,index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894e6f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.796962Z",
     "start_time": "2022-11-14T03:27:01.796962Z"
    }
   },
   "outputs": [],
   "source": [
    "feature = np.empty(shape=(0,3)) ## 创建空的np array 必须要有shape 参数\n",
    "label = np.empty(shape=(0,3))\n",
    "## 将label 和 feature 分开\n",
    "for i in range(len(file_list)):\n",
    "    label = np.append(label,np.array(file_list[i].iloc[:,-1]))\n",
    "    feature = np.append(feature,np.array(file_list[i].iloc[:,0:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc8866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.798957Z",
     "start_time": "2022-11-14T03:27:01.798957Z"
    }
   },
   "outputs": [],
   "source": [
    "feature.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f38e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.799954Z",
     "start_time": "2022-11-14T03:27:01.799954Z"
    }
   },
   "outputs": [],
   "source": [
    "title = input('本次实验的气体是（英文）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e11808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.801950Z",
     "start_time": "2022-11-14T03:27:01.801950Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t= np.linspace(0,feature.shape[0]/100,feature.shape[0])\n",
    "h2= plt.plot(t,feature[0:feature.shape[0]])\n",
    "plt.ylabel('voltage(v)')\n",
    "plt.xlabel('time(s)')\n",
    "plt.title(title)\n",
    "plt.savefig('./{}.jpg'.format(title) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195c369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.802946Z",
     "start_time": "2022-11-14T03:27:01.802946Z"
    }
   },
   "outputs": [],
   "source": [
    "## 将数据分为多组的 输入和label  （这里label 用于做one hot 只能是一维的输入  因此不适用 reshape）\n",
    "feature= feature.reshape(-1,70)\n",
    "label = label/10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0575f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-20T09:37:21.457175Z",
     "start_time": "2022-10-20T09:37:21.412295Z"
    }
   },
   "source": [
    "## 分出训练集和测试集  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117b50c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.804126Z",
     "start_time": "2022-11-14T03:27:01.804126Z"
    }
   },
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1b130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.806119Z",
     "start_time": "2022-11-14T03:27:01.806119Z"
    }
   },
   "outputs": [],
   "source": [
    "## 这里的splite 已经自带 shuffle \n",
    "features,test_feature,labels,test_label =  train_test_split(feature, label, test_size=0.2) ## 特定的库中 适用的分离 训练集和测试集的方法\n",
    "\n",
    "## 将数据类型转化为tensor\n",
    "features = torch.from_numpy(features).float()\n",
    "labels = torch.from_numpy(labels).long()\n",
    "test_feature =torch.from_numpy(test_feature).float()\n",
    "test_label = torch.from_numpy(test_label).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e66f0",
   "metadata": {},
   "source": [
    "## <span class=\"burk\">这里dataloader 是否shuffle 对预测的波动影响比较大   不懂为啥</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99303010",
   "metadata": {},
   "source": [
    "##  可能可以通过dropout 正则等方式加强稳定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fc73b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.807116Z",
     "start_time": "2022-11-14T03:27:01.807116Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 使用dataloder  和 tensordataset ： 把 多个tensor 变成 多元组 因此每个tensor的长度必须一致\n",
    "def load_array(data_arrays,batch_size,is_train = True):\n",
    "    dataset =data.TensorDataset(*data_arrays)   ## TensorDataset的作用是将多个的tensor 变成一个多元组  其中*data_array的第一维度长度必须相等\n",
    "    return data.DataLoader(dataset,batch_size,shuffle =False)\n",
    "def load_test(data_arrays,batch_size,is_test = False):\n",
    "    dataset =data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset,batch_size,shuffle =False)\n",
    "batch_size =10  # 超参数\n",
    "seed=10 ## 随机种子\n",
    "torch.manual_seed(seed)\n",
    "data_iter = load_array((features,labels),batch_size) # 训练集\n",
    "test_iter = load_test((test_feature,test_label),batch_size)  # 测试集\n",
    "\n",
    "next(iter(test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e7dc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.810107Z",
     "start_time": "2022-11-14T03:27:01.810107Z"
    }
   },
   "outputs": [],
   "source": [
    "## 定义网络 \n",
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(70, 5))\n",
    "                    #nn.Dropout(0.5)\n",
    "                    #nn.ReLU(),\n",
    "                   # nn.Linear(60,3))\n",
    "## 初始化权重 \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2804fbab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.812101Z",
     "start_time": "2022-11-14T03:27:01.812101Z"
    }
   },
   "outputs": [],
   "source": [
    "## 定义损失函数 \n",
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674be2f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.814095Z",
     "start_time": "2022-11-14T03:27:01.814095Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer = torch.optim.SGD([\n",
    "#         {\"params\":net[1].weight,'weight_decay': 1},\n",
    "#         {\"params\":net[1].bias}], lr=0.05)\n",
    "## SDG 随机梯度优方式\n",
    "trainer = torch.optim.SGD(net.parameters(),lr=0.25) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3aedda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.816090Z",
     "start_time": "2022-11-14T03:27:01.816090Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "d2l.train_ch3(net, data_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae26e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.818085Z",
     "start_time": "2022-11-14T03:27:01.818085Z"
    }
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d24a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.820080Z",
     "start_time": "2022-11-14T03:27:01.820080Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d330596",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-14T03:27:01.821077Z",
     "start_time": "2022-11-14T03:27:01.821077Z"
    }
   },
   "outputs": [],
   "source": [
    "print(net[1].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc61f24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
